{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sys import maxunicode\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/home/dafne/shared/FilterBubble/topic-modeling/Felicia-Archive/'\n",
    "\n",
    "np_data = pd.read_csv(os.path.join(path_to_data, 'np_workfile.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hits', 'Score', 'ScorePercent', 'Filename', 'V3', 'Size', 'WordCt',\n",
       "       'Title', 'headline', 'length', 'section', 'krant', 'month', 'year',\n",
       "       'day', 'date', 'yq', 'ym', 'yw', 'file', 'v1', 'V8', 'V9', 'V10_1',\n",
       "       'V10_2', 'V10_3', 'V10_4', 'V10_5', 'V11', 'V12', 'V13', 'V14', 'V16_1',\n",
       "       'V16_2', 'V16_3', 'V16_4', 'V16_5', 'V17', 'V18', 'V19', 'V22', 'V23',\n",
       "       'V24', 'V25A', 'V25B', 'V25C', 'V26', 'V27', 'V28', 'V30', 'V31', 'V32',\n",
       "       'V34a', 'V34b', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42',\n",
       "       'V43', 'V44', 'filename2', 'v9_major', 'dubbel', 'in'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(filename):\n",
    "    with open(filename) as fi:\n",
    "        text = fi.read().splitlines()\n",
    "        text = list(filter(None,text))\n",
    "        beginning = [i for i, s in enumerate(text) if 'LENGTH' in s or 'DATELINE' in s or 'LENGTE' in s]\n",
    "        end = [i for i, s in enumerate(text) if 'LOAD-DATE' in s or 'LANGUAGE' in s]\n",
    "        text = text[beginning[-1]+1:end[0]]\n",
    "        text = ''.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = dict.fromkeys(i for i in range(maxunicode) if unicodedata.category(chr(i)).startswith('P'))\n",
    "stopwords_list = set(stopwords.words('dutch'))\n",
    "stemmer=SnowballStemmer('dutch')\n",
    "\n",
    "def preprocess_pipeline(text):\n",
    "    # Remove interpunction\n",
    "    text = text.replace(u\"`\",u\"\").replace(u\"´\",u\"\").translate(tbl)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized = word_tokenize(text)\n",
    "    \n",
    "    # Stem and remove stopwords\n",
    "    stemmed = [stemmer.stem(w.lower()) for w in tokenized \n",
    "               if w.lower() not in stopwords_list and not (w.isalpha() and len(w)==1)]\n",
    "    \n",
    "    # Create bigrams - can be part of sklearn pipeline\n",
    "#     text_bigrams = [\"_\".join(tup) for tup in nltk.ngrams(stemmed,2)]\n",
    "#     text_final = stemmed + text_bigrams\n",
    "#     text_final = ' '.join(text_final)\n",
    "    text_final = ' '.join(stemmed)\n",
    "    return text_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean datafile\n",
    "df = np_data[np_data.v9_major != \" \"]\n",
    "df = df[['V3', 'v9_major', 'date']]\n",
    "df.columns = ['ID', 'topic', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = [extract_text(os.path.join(path_to_data, 'articles', n)) for n in df['ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_prep'] = df.text.apply(preprocess_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are taken from the pdf\n",
    "topic_names = {\n",
    "            1:'Macroeconomics',\n",
    "            2: 'Civil rights and minority issues',\n",
    "            3: 'Health',\n",
    "            4: 'Agriculture',\n",
    "            5: 'Labor and employment',\n",
    "            6: 'Education',\n",
    "            7: 'Environment',\n",
    "            8: 'Energy',\n",
    "            9: 'Immigration and integration',\n",
    "            10: 'Transportation',\n",
    "            12: 'Law and crime',\n",
    "            13: 'Social welfare',\n",
    "            14: 'Community development and housing',\n",
    "            15: 'Banking, finance, and commerce',\n",
    "            16: 'Defense',\n",
    "            17: 'Science, technology, and communication',\n",
    "            18: 'International trade',\n",
    "            19: 'International affairs and foreign aid',\n",
    "            20: 'Government operations',\n",
    "            21: 'Spatial planning',\n",
    "            23: 'Art, culture and entertainment',\n",
    "            24: 'Local government',\n",
    "            27: 'Weather and natural disasters',\n",
    "            28: 'Fires and accidents',\n",
    "            29: 'Sports and recreation',\n",
    "            30: 'Obituary',\n",
    "            31: 'Churches and religion',\n",
    "            99: 'Other issue'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic_name'] = [topic_names.get(int(i), np.nan) for i in df.topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>topic</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>text_prep</th>\n",
       "      <th>topic_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#100 @328419 +2073</td>\n",
       "      <td>99</td>\n",
       "      <td>1/16/1999</td>\n",
       "      <td>De andere wereld van zondagmorgen. Antropoloog...</td>\n",
       "      <td>wereld zondagmorg antropolog dr mattijs port d...</td>\n",
       "      <td>Other issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#10000 @16311398 +11159</td>\n",
       "      <td>16</td>\n",
       "      <td>12/6/2008</td>\n",
       "      <td>SAMENVATTINGDE SPEURTOCHT VAN EFRAIM ZUROFF, n...</td>\n",
       "      <td>samenvattingd speurtocht efraim zuroff nazijag...</td>\n",
       "      <td>Defense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#10004 @16327565 +1346</td>\n",
       "      <td>16</td>\n",
       "      <td>12/5/2008</td>\n",
       "      <td>Vol verwachting kloppen de hartjes van onze st...</td>\n",
       "      <td>vol verwacht klopp hartjes onz stoer mann oero...</td>\n",
       "      <td>Defense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#10004 @34719038 +2546</td>\n",
       "      <td>5</td>\n",
       "      <td>5/1/2001</td>\n",
       "      <td>Wie als nieuwkomer bij een bedrijf denkt dat h...</td>\n",
       "      <td>nieuwkomer bedrijf denkt flink salaris gestege...</td>\n",
       "      <td>Labor and employment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#10005 @37431676 +6256</td>\n",
       "      <td>3</td>\n",
       "      <td>5/7/2001</td>\n",
       "      <td>In ziekenhuizen in Hengelo en Leeuwarden wordt...</td>\n",
       "      <td>ziekenhuiz hengelo leeuward vandag gestaaktw w...</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12554</th>\n",
       "      <td>#9990 @37381637 +2880</td>\n",
       "      <td>1</td>\n",
       "      <td>5/11/2001</td>\n",
       "      <td>De consumentenprijzen in Nederland zijn in apr...</td>\n",
       "      <td>consumentenprijz nederland april jar gesteg 49...</td>\n",
       "      <td>Macroeconomics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12555</th>\n",
       "      <td>#9993 @16299444 +2081</td>\n",
       "      <td>29</td>\n",
       "      <td>12/7/2008</td>\n",
       "      <td>Ottman Bakkal is na rust ingevallen en schiet ...</td>\n",
       "      <td>ottman bakkal rust ingevall schiet psv binn dr...</td>\n",
       "      <td>Sports and recreation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12556</th>\n",
       "      <td>#9993 @34694786 +976</td>\n",
       "      <td>23</td>\n",
       "      <td>5/3/2001</td>\n",
       "      <td>BERLIJN - De vrouw van Hitlers propagandaminis...</td>\n",
       "      <td>berlijn vrouw hitler propagandaminister joseph...</td>\n",
       "      <td>Art, culture and entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12557</th>\n",
       "      <td>#9996 @37403379 +2942</td>\n",
       "      <td>1</td>\n",
       "      <td>5/9/2001</td>\n",
       "      <td>De Rabobank verzet zich als enige grote bank i...</td>\n",
       "      <td>rabobank verzet enig grot bank nederland druk ...</td>\n",
       "      <td>Macroeconomics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12558</th>\n",
       "      <td>#9998 @34705829 +3590</td>\n",
       "      <td>5</td>\n",
       "      <td>5/2/2001</td>\n",
       "      <td>Steeds meer verpleegkundigen werken naast hun ...</td>\n",
       "      <td>sted verpleegkund werk naast ban ziekenhuis al...</td>\n",
       "      <td>Labor and employment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11124 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ID topic       date  \\\n",
       "0           #100 @328419 +2073    99  1/16/1999   \n",
       "1      #10000 @16311398 +11159    16  12/6/2008   \n",
       "2       #10004 @16327565 +1346    16  12/5/2008   \n",
       "3       #10004 @34719038 +2546     5   5/1/2001   \n",
       "4       #10005 @37431676 +6256     3   5/7/2001   \n",
       "...                        ...   ...        ...   \n",
       "12554    #9990 @37381637 +2880     1  5/11/2001   \n",
       "12555    #9993 @16299444 +2081    29  12/7/2008   \n",
       "12556     #9993 @34694786 +976    23   5/3/2001   \n",
       "12557    #9996 @37403379 +2942     1   5/9/2001   \n",
       "12558    #9998 @34705829 +3590     5   5/2/2001   \n",
       "\n",
       "                                                    text  \\\n",
       "0      De andere wereld van zondagmorgen. Antropoloog...   \n",
       "1      SAMENVATTINGDE SPEURTOCHT VAN EFRAIM ZUROFF, n...   \n",
       "2      Vol verwachting kloppen de hartjes van onze st...   \n",
       "3      Wie als nieuwkomer bij een bedrijf denkt dat h...   \n",
       "4      In ziekenhuizen in Hengelo en Leeuwarden wordt...   \n",
       "...                                                  ...   \n",
       "12554  De consumentenprijzen in Nederland zijn in apr...   \n",
       "12555  Ottman Bakkal is na rust ingevallen en schiet ...   \n",
       "12556  BERLIJN - De vrouw van Hitlers propagandaminis...   \n",
       "12557  De Rabobank verzet zich als enige grote bank i...   \n",
       "12558  Steeds meer verpleegkundigen werken naast hun ...   \n",
       "\n",
       "                                               text_prep  \\\n",
       "0      wereld zondagmorg antropolog dr mattijs port d...   \n",
       "1      samenvattingd speurtocht efraim zuroff nazijag...   \n",
       "2      vol verwacht klopp hartjes onz stoer mann oero...   \n",
       "3      nieuwkomer bedrijf denkt flink salaris gestege...   \n",
       "4      ziekenhuiz hengelo leeuward vandag gestaaktw w...   \n",
       "...                                                  ...   \n",
       "12554  consumentenprijz nederland april jar gesteg 49...   \n",
       "12555  ottman bakkal rust ingevall schiet psv binn dr...   \n",
       "12556  berlijn vrouw hitler propagandaminister joseph...   \n",
       "12557  rabobank verzet enig grot bank nederland druk ...   \n",
       "12558  sted verpleegkund werk naast ban ziekenhuis al...   \n",
       "\n",
       "                           topic_name  \n",
       "0                         Other issue  \n",
       "1                             Defense  \n",
       "2                             Defense  \n",
       "3                Labor and employment  \n",
       "4                              Health  \n",
       "...                               ...  \n",
       "12554                  Macroeconomics  \n",
       "12555           Sports and recreation  \n",
       "12556  Art, culture and entertainment  \n",
       "12557                  Macroeconomics  \n",
       "12558            Labor and employment  \n",
       "\n",
       "[11124 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove data with empty text\n",
    "df = df[df.text!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove data with rare topics\n",
    "df = df[~df.topic_name.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train - val -test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df.index, test_size=0.2, stratify=df['topic_name'], random_state=0)\n",
    "df['sample'] = ''\n",
    "df.loc[train, 'sample'] = 'train'\n",
    "df.loc[test,'sample'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(path_to_data, 'preprocessed.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
